# Large Language Model Configuration
# Primary model configuration
primary:
  provider: "google"  # openai, anthropic, azure_openai, huggingface, ollama
  base_url: "https://generativelanguage.googleapis.com"
  model_name: "gemini-2.0-flash"
  temperature: 0.1
  max_tokens: 2048
  timeout: 30
  
# Fallback models for reliability
fallback:
  - provider: "openai"
    model: "gpt-3.5-turbo"
    temperature: 0.1
    max_tokens: 2048
    
  - provider: "ollama"
    model: "llama2"
    base_url: "http://localhost:11434"  


# # Model performance settings
# performance:
#   concurrent_requests: 5
#   retry_attempts: 3
#   retry_delay: 1.0
#   enable_streaming: true
#   enable_function_calling: true
